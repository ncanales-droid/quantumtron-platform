"""
Florence API Endpoints
"""

import time
from typing import Dict, Any
from fastapi import APIRouter, Depends, HTTPException, status
from fastapi.responses import JSONResponse

from app.schemas.florence import (
    ResearchQuestionRequest,
    StatisticalAnalysisRequest,
    KnowledgeBaseRequest,
    ChatRequest,
    ResearchAnalysisResponse,
    StatisticalResultResponse,
    KnowledgeBaseResponse,
    ChatResponse,
    ErrorResponse
)

from app.api.deps import (
    get_deepseek_client,
    get_knowledge_base,
    get_statistical_engine,
    get_response_formatter,
    get_florence_orchestrator
)

router = APIRouter(prefix="/florence", tags=["florence"])


@router.get("/health", response_model=Dict[str, Any])
async def health_check():
    """Health check endpoint for Florence"""
    from app.services.florence import (
        deepseek_client,
        knowledge_base,
        statistical_engine,
        response_formatter
    )
    
    components = {
        "deepseek": bool(deepseek_client),
        "knowledge_base": bool(knowledge_base),
        "statistical_engine": bool(statistical_engine),
        "response_formatter": bool(response_formatter),
        "api_version": "1.0.0"
    }
    
    all_healthy = all(components.values())
    
    return {
        "status": "healthy" if all_healthy else "degraded",
        "components": components,
        "message": "Florence PhD Research Agent"
    }


@router.post("/chat", response_model=ChatResponse)
async def chat_with_florence(
    request: ChatRequest,
    deepseek_client = Depends(get_deepseek_client)
):
    """
    Chat with Florence PhD Agent
    
    - **message**: Your question or message to Florence
    - **context**: Additional context for the conversation
    - **temperature**: Creativity of response (0.0 to 2.0)
    - **max_tokens**: Maximum length of response
    """
    try:
        start_time = time.time()
        
        response = deepseek_client.research_assistance(
            prompt=request.message,
            context=request.context or "",
            temperature=request.temperature,
            max_tokens=request.max_tokens
        )
        
        processing_time_ms = (time.time() - start_time) * 1000
        # Save query to SQLite database
        try:
            query_id = florence_db.save_query(
                question=request.message,
                response=response
            )
            print(f"💾 Query saved to SQLite: {query_id}")
        except Exception as db_error:
            print(f"⚠️  Could not save to database: {db_error}")
            query_id = "not_saved"
        
        return ChatResponse(
            message=request.message,
            response=response,
            model=deepseek_client.model,
            processing_time_ms=round(processing_time_ms, 2)
        )
        
    except Exception as e:
        raise HTTPException(
            status_code=status.HTTP_500_INTERNAL_SERVER_ERROR,
            detail=f"Chat failed: {str(e)}"
        )


@router.post("/analyze/statistical", response_model=StatisticalResultResponse)
async def statistical_analysis(
    request: StatisticalAnalysisRequest,
    statistical_engine = Depends(get_statistical_engine)
):
    """
    Perform statistical analysis
    
    - **data**: Dictionary with groups as keys and lists of values
    - **analysis_type**: Type of test (t_test, anova, correlation, regression)
    - **options**: Additional options for the analysis
    """
    try:
        start_time = time.time()
        
        # Convert data to numpy arrays
        import numpy as np
        data_arrays = {k: np.array(v) for k, v in request.data.items()}
        
        # Perform analysis based on type
        if request.analysis_type == "t_test":
            if len(data_arrays) != 2:
                raise ValueError("t-test requires exactly two groups")
            
            groups = list(data_arrays.values())
            result = statistical_engine.t_test(
                groups[0], 
                groups[1],
                **request.options
            )
            
        elif request.analysis_type == "anova":
            groups = list(data_arrays.values())
            result = statistical_engine.anova(groups, **request.options)
            
        elif request.analysis_type == "correlation":
            if len(data_arrays) != 2:
                raise ValueError("Correlation requires exactly two variables")
            
            vars_list = list(data_arrays.values())
            result = statistical_engine.correlation_analysis(
                vars_list[0],
                vars_list[1],
                **request.options
            )
            
        elif request.analysis_type == "describe":
            # Descriptive statistics
            if len(data_arrays) == 1:
                data = list(data_arrays.values())[0]
                variable_names = list(data_arrays.keys())
            else:
                data = list(data_arrays.values())
                variable_names = list(data_arrays.keys())
            
            description = statistical_engine.describe_data(data, variable_names)
            
            # Create a StatisticalResultResponse from description
            result_dict = {
                "test_name": "Descriptive Statistics",
                "statistic": 0.0,
                "p_value": 1.0,
                "interpretation": "Descriptive analysis completed",
                "assumptions": {},
                "recommendations": ["Review distribution plots", "Check for outliers"],
                "raw_result": description
            }
            return StatisticalResultResponse(**result_dict)
            
        else:
            raise ValueError(f"Unsupported analysis type: {request.analysis_type}")
        
        # Convert to response model
        response = StatisticalResultResponse(
            test_name=result.test_name,
            statistic=result.statistic,
            p_value=result.p_value,
            effect_size=result.effect_size,
            confidence_interval=list(result.ci_95) if result.ci_95 else None,
            interpretation=result.interpretation,
            assumptions=result.assumptions or {},
            recommendations=result.recommendations or [],
            raw_result=result.to_dict()
        )
        
        return response
        
    except ValueError as e:
        raise HTTPException(
            status_code=status.HTTP_400_BAD_REQUEST,
            detail=str(e)
        )
    except Exception as e:
        raise HTTPException(
            status_code=status.HTTP_500_INTERNAL_SERVER_ERROR,
            detail=f"Statistical analysis failed: {str(e)}"
        )


@router.post("/analyze/research", response_model=ResearchAnalysisResponse)
async def research_analysis(
    request: ResearchQuestionRequest,
    deepseek_client = Depends(get_deepseek_client),
    knowledge_base = Depends(get_knowledge_base),
    statistical_engine = Depends(get_statistical_engine),
    response_formatter = Depends(get_response_formatter)
):
    """
    Complete research question analysis
    
    - **question**: Research question to analyze
    - **context**: Additional context
    - **data**: Optional dataset for statistical analysis
    - **analysis_type**: Type of analysis (auto, t_test, etc.)
    """
    try:
        start_time = time.time()
        
        # 1. Search knowledge base for context
        kb_context = ""
        if knowledge_base:
            kb_results = knowledge_base.search(request.question, top_k=3)
            if kb_results:
                kb_context = "\n".join([r["text"] for r in kb_results[:2]])
        
        # 2. Perform statistical analysis if data provided
        statistical_result = None
        if request.data:
            try:
                # Convert data to numpy arrays
                import numpy as np
                data_arrays = {k: np.array(v) for k, v in request.data.items()}
                
                if len(data_arrays) >= 2 and request.analysis_type in ["auto", "t_test"]:
                    groups = list(data_arrays.values())
                    stat_result = statistical_engine.t_test(groups[0], groups[1])
                    statistical_result = StatisticalResultResponse(
                        test_name=stat_result.test_name,
                        statistic=stat_result.statistic,
                        p_value=stat_result.p_value,
                        effect_size=stat_result.effect_size,
                        confidence_interval=list(stat_result.ci_95) if stat_result.ci_95 else None,
                        interpretation=stat_result.interpretation,
                        assumptions=stat_result.assumptions or {},
                        recommendations=stat_result.recommendations or [],
                        raw_result=stat_result.to_dict()
                    )
            except Exception as e:
                print(f"Statistical analysis warning: {e}")
        
        # 3. Get AI interpretation
        prompt = f"""
        Research Question: {request.question}
        
        {f"Context: {request.context}" if request.context else ""}
        {f"Knowledge Base Context: {kb_context}" if kb_context else ""}
        {f"Statistical Results: {statistical_result.interpretation if statistical_result else 'No statistical data provided'}"}
        
        Please provide a comprehensive research analysis including:
        1. Interpretation of the question
        2. Methodology suggestions
        3. Data analysis approach
        4. Potential limitations
        5. Recommendations for further research
        """
        
        ai_response = deepseek_client.research_assistance(
            prompt=prompt,
            max_tokens=800,
            temperature=0.7
        )
        
        # 4. Generate formatted report
        formatted_report = None
        if response_formatter:
            report_data = {
                "title": f"Research Analysis: {request.question[:50]}...",
                "type": "research_analysis",
                "content": ai_response,
                "statistical_results": statistical_result.dict() if statistical_result else None,
                "metadata": {
                    "question": request.question,
                    "has_data": bool(request.data),
                    "kb_context_used": bool(kb_context)
                }
            }
            
            formatted_report = response_formatter.format_response(
                report_data,
                output_format="markdown"
            )
        
        processing_time_ms = (time.time() - start_time) * 1000
        
        return ResearchAnalysisResponse(
            question=request.question,
            statistical_analysis=statistical_result,
            ai_interpretation=ai_response,
            knowledge_context=kb_results if 'kb_results' in locals() else None,
            formatted_report=formatted_report,
            recommendations=["Review analysis", "Consider additional data sources"],
            processing_time_ms=round(processing_time_ms, 2)
        )
        
    except Exception as e:
        raise HTTPException(
            status_code=status.HTTP_500_INTERNAL_SERVER_ERROR,
            detail=f"Research analysis failed: {str(e)}"
        )


@router.post("/knowledge", response_model=KnowledgeBaseResponse)
async def knowledge_base_operations(
    request: KnowledgeBaseRequest,
    knowledge_base = Depends(get_knowledge_base)
):
    """
    Knowledge Base operations
    
    - **operation**: add, search, query, clear, stats
    - **content**: Text content (for add operation)
    - **query**: Search query (for search/query operations)
    - **metadata**: Document metadata (for add operation)
    """
    try:
        start_time = time.time()
        
        if request.operation == "add":
            if not request.content:
                raise ValueError("Content is required for add operation")
            
            doc_id = knowledge_base.add_document(
                request.content,
                metadata=request.metadata
            )
            
            return KnowledgeBaseResponse(
                operation="add",
                success=True,
                message=f"Document added with ID: {doc_id}",
                data={"document_id": doc_id}
            )
            
        elif request.operation == "search":
            if not request.query:
                raise ValueError("Query is required for search operation")
            
            results = knowledge_base.search(request.query, top_k=10)
            
            return KnowledgeBaseResponse(
                operation="search",
                success=True,
                message=f"Found {len(results)} documents",
                documents=results
            )
            
        elif request.operation == "query":
            if not request.query:
                raise ValueError("Query is required for query operation")
            
            context_result = knowledge_base.query_with_context(request.query)
            
            return KnowledgeBaseResponse(
                operation="query",
                success=True,
                message=f"Context retrieved with {context_result['total_documents']} documents",
                data=context_result
            )
            
        elif request.operation == "stats":
            stats = knowledge_base.get_statistics()
            
            return KnowledgeBaseResponse(
                operation="stats",
                success=True,
                message="Knowledge Base statistics",
                statistics=stats
            )
            
        elif request.operation == "clear":
            # Require confirmation in metadata
            if request.metadata.get("confirm") != "yes":
                raise ValueError("Clear operation requires confirmation")
            
            knowledge_base.clear(confirm=True)
            
            return KnowledgeBaseResponse(
                operation="clear",
                success=True,
                message="Knowledge Base cleared successfully"
            )
            
        else:
            raise ValueError(f"Unsupported operation: {request.operation}")
            
    except ValueError as e:
        raise HTTPException(
            status_code=status.HTTP_400_BAD_REQUEST,
            detail=str(e)
        )
    except Exception as e:
        raise HTTPException(
            status_code=status.HTTP_500_INTERNAL_SERVER_ERROR,
            detail=f"Knowledge Base operation failed: {str(e)}"
        )


@router.get("/models")
async def get_available_models(
    deepseek_client = Depends(get_deepseek_client)
):
    """Get available AI models"""
    try:
        models = deepseek_client.get_available_models()
        return {"models": models, "current_model": deepseek_client.model}
    except Exception as e:
        return {"models": [deepseek_client.model], "error": str(e)}


@router.post("/format")
async def format_response(
    content: Dict[str, Any],
    format_type: str = "markdown",
    response_formatter = Depends(get_response_formatter)
):
    """Format content using response formatter"""
    try:
        formatted = response_formatter.format_response(content, output_format=format_type)
        return {"formatted": formatted, "format": format_type}
    except Exception as e:
        raise HTTPException(
            status_code=status.HTTP_500_INTERNAL_SERVER_ERROR,
            detail=f"Formatting failed: {str(e)}"
        )
# Agregar esto cerca de las otras importaciones en florence.py
from app.db_simple import florence_db

@router.get("/db/stats")
async def get_database_stats():
    """Get SQLite database statistics"""
    try:
        stats = florence_db.get_stats()
        return {
            "status": "ok",
            "database": stats,
            "timestamp": datetime.now().isoformat()
        }
    except Exception as e:
        raise HTTPException(
            status_code=status.HTTP_500_INTERNAL_SERVER_ERROR,
            detail=f"Failed to get stats: {str(e)}"
        )


@router.get("/db/history")
async def get_query_history(limit: int = 20):
    """Get recent query history"""
    try:
        queries = florence_db.get_recent_queries(limit=limit)
        return {
            "status": "ok",
            "count": len(queries),
            "queries": queries,
            "timestamp": datetime.now().isoformat()
        }
    except Exception as e:
        raise HTTPException(
            status_code=status.HTTP_500_INTERNAL_SERVER_ERROR,
            detail=f"Failed to get history: {str(e)}"
        )


@router.post("/db/backup")
async def create_backup():
    """Create database backup"""
    try:
        backup_path = florence_db.backup()
        return {
            "status": "ok",
            "message": "Backup created successfully",
            "backup_path": backup_path,
            "timestamp": datetime.now().isoformat()
        }
    except Exception as e:
        raise HTTPException(
            status_code=status.HTTP_500_INTERNAL_SERVER_ERROR,
            detail=f"Backup failed: {str(e)}"
        )


@router.post("/db/cleanup")
async def cleanup_database(days_to_keep: int = 30):
    """Cleanup old data (keep last X days)"""
    try:
        result = florence_db.cleanup_old_data(days_to_keep)
        return {
            "status": "ok",
            "message": f"Cleanup completed. Kept last {days_to_keep} days.",
            "result": result,
            "timestamp": datetime.now().isoformat()
        }
    except Exception as e:
        raise HTTPException(
            status_code=status.HTTP_500_INTERNAL_SERVER_ERROR,
            detail=f"Cleanup failed: {str(e)}"
        )


@router.get("/db/kb")
async def get_knowledge_base_docs(limit: int = 50):
    """Get Knowledge Base documents from database"""
    try:
        documents = florence_db.get_kb_documents(limit=limit)
        return {
            "status": "ok",
            "count": len(documents),
            "documents": documents,
            "timestamp": datetime.now().isoformat()
        }
    except Exception as e:
        raise HTTPException(
            status_code=status.HTTP_500_INTERNAL_SERVER_ERROR,
            detail=f"Failed to get KB documents: {str(e)}"
        )
